{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Regressao Logística (Redes Complexas).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMiv6Yu5GSWqPyAc7yFyK59",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davi-santos/LogisticRegression-CervicalCancer/blob/main/Regressao_Log%C3%ADstica_(Redes_Complexas).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfMq0HZaFtEx"
      },
      "source": [
        "# Redes Complexas - Regressão Logística"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FsLd5TkF2zP"
      },
      "source": [
        "Este projeto consiste em apresentar um modelo de *Machine Learning* (do inglês, aprendizado de máquina) em uma base de dados da área médica para a disciplina de Redes Complexas. Para isto, definiu-se para o modelo o classificador Regressão Logística. As etapas para obter o modelo de aprendizado de máquina estão contidas no fluxograma abaixo:\n",
        "\n",
        " <center><img src='https://drive.google.com/uc?id=1dTVvf0HMEEk61T_qOs8pLn83yF1YrLvR'  width=\"450\" height=\"300\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBUBGjf6hBc6"
      },
      "source": [
        "### 1) Aquisição da Base de Dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mye22-RxJl4I"
      },
      "source": [
        "Os dados foram obtidos no repositório UCI *Machine Learning Repository* e a base de dados escolhida foi a *Cervical Cancer Behavior Risk Data Set* (Conjunto de dados de risco de comportamento de câncer cervical).\n",
        "\n",
        "link: https://archive.ics.uci.edu/ml/datasets/Cervical+Cancer+Behavior+Risk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOOudg_XFkS0",
        "outputId": "7b01c76a-006b-44c4-d691-a4a3d9a1b345",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/00537/sobar-72.csv')\n",
        "\n",
        "print(df)\n",
        "print(df.columns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    behavior_sexualRisk  behavior_eating  ...  empowerment_desires  ca_cervix\n",
            "0                    10               13  ...                    8          1\n",
            "1                    10               11  ...                    4          1\n",
            "2                    10               15  ...                   15          1\n",
            "3                    10               11  ...                    4          1\n",
            "4                     8               11  ...                    7          1\n",
            "..                  ...              ...  ...                  ...        ...\n",
            "67                   10               14  ...                    9          0\n",
            "68                   10               12  ...                   14          0\n",
            "69                   10                8  ...                   10          0\n",
            "70                    9               12  ...                   15          0\n",
            "71                   10               14  ...                   15          0\n",
            "\n",
            "[72 rows x 20 columns]\n",
            "Index(['behavior_sexualRisk', 'behavior_eating', 'behavior_personalHygine',\n",
            "       'intention_aggregation', 'intention_commitment', 'attitude_consistency',\n",
            "       'attitude_spontaneity', 'norm_significantPerson', 'norm_fulfillment',\n",
            "       'perception_vulnerability', 'perception_severity',\n",
            "       'motivation_strength', 'motivation_willingness',\n",
            "       'socialSupport_emotionality', 'socialSupport_appreciation',\n",
            "       'socialSupport_instrumental', 'empowerment_knowledge',\n",
            "       'empowerment_abilities', 'empowerment_desires', 'ca_cervix'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYYwz-W0MS8r"
      },
      "source": [
        "### 2) Preprocessamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXJ4SopNMl1c"
      },
      "source": [
        "Esta etapa consistem em tratar e preparar os dados para o classificador de aprendizado de máquina. Para isto, deve-se:\n",
        "\n",
        "\n",
        "*   Verificar valores incompletos;\n",
        "*   Padronizar os dados para a distribuição normal\n",
        "*   Separar os dados em atributos e classe\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdIIREstMlSW",
        "outputId": "1ace1dfa-2b46-4808-cb03-02f54e4031c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "bool_series = pd.notnull(df)\n",
        "print(df[bool_series].shape)\n",
        "\n",
        "#X representa as amostras e y as classes\n",
        "X = df.iloc[:, :18].values\n",
        "y = df.iloc[:, 19].values\n",
        "\n",
        "#escalar os valores de X para o padrao\n",
        "scaler = StandardScaler().fit(X)\n",
        "X = scaler.transform(X)\n",
        "\n",
        "#print(X)\n",
        "#print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(72, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2F4zK6f6MpxY"
      },
      "source": [
        "### 3) Treinamento do Modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRbsk5BZMzh-"
      },
      "source": [
        "Deve-se lembrar que um modelo de aprendizado de máquina tem por objetivo aprender com os dados e ser capaz de classificar novos dados. Isto é, nosso modelo deve ser capaz de generalizar. O esquema abaixo ilustra as etapas de treinamento e avaliação de um modelo:\n",
        "\n",
        "<center><img src='https://drive.google.com/uc?id=1aF3ul3NMOuHHZWmszOahIfckAhanNm4-'  width=\"770\" height=\"320\"></center>\n",
        "</br>\n",
        "\n",
        "Para atingir a finalidade de generalização, divide-se a base de dados em dados de treinamento e teste. A base de treinamento é a responsável por treinar o modelo a definir uma função de classificar corretamente as amostras. A fim de avaliação, utiliza-se a base de teste para verificar a capacidade de generalização para novos dados. Ao final, devemos evitar dois casos extremos: overfitting e underfitting.\n",
        "\n",
        "<center><img src='https://drive.google.com/uc?id=130RxDCc4mXongDaIMjWRR0k5LxAfU9MH'  width=\"450\" height=\"100\"></center>\n",
        "\n",
        "A figura acima mostra um exemplo de divisão da base de dados. Utilizaremos o train_test_split do sklearn para dividir os dados de treinamento e teste. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWpkQGo9hecm"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.3, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auQW0XOliLFB"
      },
      "source": [
        "Na fase de treinamento do modelo, utilizaremos duas abordagens para aumentar a generalização do algoritmo: validação cruzada e tunagem de parâmetros. a validação cruzada, em resumo, consiste de dividir a base de dados de treinamento em subpastas e testar diferentes divisões de treinamento e teste. A figura abaixo mostra o processo de validação cruzada.\n",
        "\n",
        "<center><img src='https://drive.google.com/uc?id=1galS0sZk5xmjGY-sbWjmbIk12klbE74w'  width=\"650\" height=\"400\"></center>\n",
        "\n",
        "A tunagem de parâmetros consiste em testar diferentes parâmetros para aumentar a precisão do modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UylvNopDZHWt",
        "outputId": "17b1b38f-27ee-404f-b39e-b6007f242ddb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "#Validação cruzada\n",
        "scores = cross_val_score(LogisticRegression(), X_train, y_train, cv=10)\n",
        "print(\"Mean cross-validation accuracy: {}\".format(np.mean(scores)))\n",
        "print(scores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean cross-validation accuracy: 0.9\n",
            "[1.  0.5 0.5 1.  1.  1.  1.  1.  1.  1. ]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 5 members, which is less than n_splits=10.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-W7UsFwb-Y9",
        "outputId": "0a1b6c93-5c93-44bd-d3f5-11efdc234585",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#GridSearch para tunagem de parâmetros\n",
        "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10]}\n",
        "grid = GridSearchCV(LogisticRegression(), param_grid, cv=10)\n",
        "grid.fit(X_train, y_train)\n",
        "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\n",
        "print(\"Best parameters: \", grid.best_params_)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 5 members, which is less than n_splits=10.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best cross-validation score: 0.90\n",
            "Best parameters:  {'C': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTVVAGbFM8zE"
      },
      "source": [
        "### 4) Avaliação do Modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pf12rNFWd6O_",
        "outputId": "cc31952a-1eb7-4589-c44c-d83f75e14fa7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Usando no teste pra ver no que dá, né\n",
        "\n",
        "print(grid.score(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9019607843137255\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}